#  Conversational Knowledge Bot

A locally deployable Conversational Knowledge Bot that supports contextual follow-up questions by combining:

- External web search (DuckDuckGo)
- Extractive Question Answering (RoBERTa)
- Lightweight conversational memory
- Streamlit chat UI

Built without OpenAI or Ollama ‚Äî fully CPU-based.

---

##  Features

-  Searches live web data using DuckDuckGo  
-  Extracts factual answers using HuggingFace QA model  
-  Remembers previous entity for follow-up questions (e.g., ‚ÄúWhere did he study?‚Äù)  
-  Streamlit chat interface  
-  CLI support  
-  No paid APIs required  

---

## üèó Architecture

```bash
User
 ‚Üì
Streamlit / CLI
 ‚Üì
DuckDuckGo Search (DDGS)
 ‚Üì
RoBERTa Question Answering Model
 ‚Üì
Answer Extraction
 ‚Üì
Entity Memory (for follow-ups)

```

Tech Stack

Python 3.10+

HuggingFace Transformers

deepset/roberta-base-squad2 (QA Model)

DuckDuckGo Search (ddgs)

Streamlit

Installation

Create environment:

conda create -n kbot python=3.10
conda activate kbot


Install dependencies:

pip install transformers torch streamlit ddgs

Run CLI
python cli.py

Run Streamlit UI
streamlit run app.py


Open in browser:

http://localhost:8501

üí¨ Sample Chat
User: who is ceo of tesla
Bot: Elon Musk

User: where did he study
Bot: University of Pennsylvania

User: where was he born
Bot: Pretoria

